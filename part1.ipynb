{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "import datetime\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtsvg(index,x_train,y_train):#save one pic for each category\n",
    "    for i in range(len(x_train)):\n",
    "        if y_train[i]==index:\n",
    "            plt.imsave(str(index)+\".png\",x_train[i])\n",
    "            print(\"The shape of the category\"+str(index)+\" is \"+str(x_train[i].shape))\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the category0 is (28, 28)\n",
      "The shape of the category1 is (28, 28)\n",
      "The shape of the category2 is (28, 28)\n",
      "The shape of the category3 is (28, 28)\n",
      "The shape of the category4 is (28, 28)\n",
      "The shape of the category5 is (28, 28)\n",
      "The shape of the category6 is (28, 28)\n",
      "The shape of the category7 is (28, 28)\n",
      "The shape of the category8 is (28, 28)\n",
      "The shape of the category9 is (28, 28)\n",
      "The size of train set is 60000\n",
      "The size of test set is 10000\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    dtsvg(i,x_train,y_train)\n",
    "print(\"The size of train set is \"+str(len(x_train)))\n",
    "print(\"The size of test set is \"+str(len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 9.9656 - accuracy: 0.7409\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 1.2990 - accuracy: 0.7053\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.7819 - accuracy: 0.7200\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.6745 - accuracy: 0.7443\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.5899 - accuracy: 0.7833\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.8141\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.8311\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8364\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8460\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c90393d188>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28,28)))\n",
    "model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,batch_size=200,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 575us/step - loss: 0.5695 - accuracy: 0.8192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5695033669471741, 0.8191999793052673]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN need a 4D input\n",
    "x_train1 = np.expand_dims(x_train, axis=3)\n",
    "x_test1 = np.expand_dims(x_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 3s 12ms/step - loss: 0.5982 - accuracy: 0.7855\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 0.4235 - accuracy: 0.8422\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 0.3898 - accuracy: 0.8541\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 0.3643 - accuracy: 0.8635\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 3s 12ms/step - loss: 0.3540 - accuracy: 0.8667 0s - loss:\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 0.3372 - accuracy: 0.8742\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 3s 12ms/step - loss: 0.3257 - accuracy: 0.8771\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 0.3160 - accuracy: 0.8809\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 3s 12ms/step - loss: 0.3086 - accuracy: 0.8831\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 3s 12ms/step - loss: 0.2984 - accuracy: 0.8874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c90da48148>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2=keras.Sequential()\n",
    "model2.add(tf.keras.layers.Conv2D(filters=10,kernel_size=2,activation='tanh',input_shape=(28,28,1)))\n",
    "model2.add(tf.keras.layers.MaxPool2D(pool_size=(6,3)))\n",
    "model2.add(tf.keras.layers.Flatten())#make the data into array\n",
    "model2.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "model2.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "model2.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model2.fit(x_train1,y_train,batch_size=200,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3526 - accuracy: 0.8689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35259565711021423, 0.8689000010490417]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x_test1,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "90/90 [==============================] - 18s 196ms/step - loss: 0.9149 - accuracy: 0.6837 - val_loss: 0.5485 - val_accuracy: 0.8075\n",
      "Epoch 2/10\n",
      "90/90 [==============================] - 18s 195ms/step - loss: 0.4952 - accuracy: 0.8285 - val_loss: 0.4200 - val_accuracy: 0.8540\n",
      "Epoch 3/10\n",
      "90/90 [==============================] - 18s 199ms/step - loss: 0.3998 - accuracy: 0.8596 - val_loss: 0.3630 - val_accuracy: 0.8748\n",
      "Epoch 4/10\n",
      "90/90 [==============================] - 17s 194ms/step - loss: 0.3573 - accuracy: 0.8755 - val_loss: 0.3313 - val_accuracy: 0.8849\n",
      "Epoch 5/10\n",
      "90/90 [==============================] - 17s 194ms/step - loss: 0.3256 - accuracy: 0.8849 - val_loss: 0.3265 - val_accuracy: 0.8845\n",
      "Epoch 6/10\n",
      "90/90 [==============================] - 18s 196ms/step - loss: 0.3029 - accuracy: 0.8917 - val_loss: 0.2992 - val_accuracy: 0.8947\n",
      "Epoch 7/10\n",
      "90/90 [==============================] - 17s 194ms/step - loss: 0.2844 - accuracy: 0.8972 - val_loss: 0.2973 - val_accuracy: 0.8915\n",
      "Epoch 8/10\n",
      "90/90 [==============================] - 17s 192ms/step - loss: 0.2714 - accuracy: 0.9016 - val_loss: 0.2898 - val_accuracy: 0.8953\n",
      "Epoch 9/10\n",
      "90/90 [==============================] - 17s 190ms/step - loss: 0.2582 - accuracy: 0.9065 - val_loss: 0.2763 - val_accuracy: 0.8995\n",
      "Epoch 10/10\n",
      "90/90 [==============================] - 17s 191ms/step - loss: 0.2449 - accuracy: 0.9105 - val_loss: 0.2650 - val_accuracy: 0.9037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c911063288>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3=keras.Sequential()\n",
    "model3.add(tf.keras.layers.Conv2D(filters=50,kernel_size=3,activation='relu',input_shape=(28,28,1),padding='SAME'))#initial pattern\n",
    "model3.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "model3.add(tf.keras.layers.Conv2D(filters=50,kernel_size=2,activation='relu',padding='SAME'))#high level pattern\n",
    "model3.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "model3.add(tf.keras.layers.Dropout(rate=0.25))#avoid overfitting\n",
    "model3.add(tf.keras.layers.Flatten())\n",
    "model3.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "model3.add(tf.keras.layers.Dense(64,activation='tanh'))\n",
    "model3.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "model3.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model3.fit(x_train1,y_train,batch_size=500,epochs=10,validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2855 - accuracy: 0.9006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2854532301425934, 0.900600016117096]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(x_test1,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
